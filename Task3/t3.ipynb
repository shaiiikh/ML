{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets, models, transforms\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "## Define file directories\n",
    "file_dir = \"./data-full\"\n",
    "output_dir = \"./output/SVM_trained.pth\"\n",
    "out_report_dir = './output/classification_report.txt'\n",
    "TRAIN = \"train\"\n",
    "TEST = \"test\"\n",
    "\n",
    "\n",
    "def get_data(file_dir):\n",
    "    \"\"\"\n",
    "    Load and transform the data using PyTorch's ImageFolder and DataLoader.\n",
    "\n",
    "    Args:\n",
    "        file_dir (str): Directory path containing the data.\n",
    "        TRAIN (str, optional): Name of the training dataset directory. Defaults to 'train'.\n",
    "        VAL (str, optional): Name of the validation dataset directory. Defaults to 'val'.\n",
    "        TEST (str, optional): Name of the test dataset directory. Defaults to 'test'.\n",
    "\n",
    "    Returns:\n",
    "        datasets_img (dict): Dictionary containing the datasets for training, validation, and test.\n",
    "        datasets_size (dict): Dictionary containing the sizes of the datasets.\n",
    "        dataloaders (dict): Dictionary containing the data loaders for training, validation, and test.\n",
    "        class_names (list): List of class names.\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Loading data...\")\n",
    "    # Initialize data transformations\n",
    "    data_transform = {\n",
    "        TRAIN: transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        ),\n",
    "        TEST: transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(254), \n",
    "                transforms.CenterCrop(224), \n",
    "                transforms.ToTensor()\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "    # Initialize datasets and apply transformations\n",
    "    datasets_img = {\n",
    "        file: datasets.ImageFolder(\n",
    "            os.path.join(file_dir, file), transform=data_transform[file]\n",
    "        )\n",
    "        for file in [TRAIN, TEST]\n",
    "    }\n",
    "    # Load data into dataloaders\n",
    "    dataloaders = {\n",
    "        file: torch.utils.data.DataLoader(\n",
    "            datasets_img[file], batch_size=8, shuffle=True, num_workers=4\n",
    "        )\n",
    "        for file in [TRAIN, TEST]\n",
    "    }\n",
    "    # Get class names and dataset sizes\n",
    "    class_names = datasets_img[TRAIN].classes\n",
    "    datasets_size = {file: len(datasets_img[file]) for file in [TRAIN, TEST]}\n",
    "    for file in [TRAIN, TEST]:\n",
    "        print(f\"[INFO] Loaded {datasets_size[file]} images under {file}\")\n",
    "    print(f\"Classes: {class_names}\")\n",
    "\n",
    "    return datasets_img, datasets_size, dataloaders, class_names\n",
    "\n",
    "\n",
    "def get_vgg16_modified_model(weights=models.VGG16_BN_Weights.DEFAULT):\n",
    "    \"\"\"\n",
    "    Retrieve the VGG-16 pre-trained model and remove the classifier layers.\n",
    "\n",
    "    Args:\n",
    "        model_dir (str, optional): Directory path for loading a pre-trained model state dictionary. Defaults to ''.\n",
    "        weights (str or dict, optional): Pre-trained model weights. Defaults to models.vgg16_bn(pretrained=True).state_dict().\n",
    "        len_target (int, optional): Number of output classes. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        vgg16 (torchvision.models.vgg16): VGG-16 model with removed classifier.\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Getting VGG-16 pre-trained model...\")\n",
    "    # Load VGG-16 pretrained model\n",
    "    vgg16 = models.vgg16_bn(weights)\n",
    "    # Freeze training for all layers\n",
    "    for param in vgg16.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Remove the classifier layers\n",
    "    features = list(vgg16.classifier.children())[:-7]\n",
    "    # Replace the model's classifier\n",
    "    vgg16.classifier = nn.Sequential(*features)\n",
    "    # print(vgg16)\n",
    "    return vgg16\n",
    "\n",
    "\n",
    "def get_classification_report(truth_values, pred_values):\n",
    "    \"\"\"\n",
    "    Generate a classification report and confusion matrix based on ground truth and predicted labels.\n",
    "\n",
    "    Args:\n",
    "        truth_values (list): List of ground truth labels.\n",
    "        pred_values (list): List of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    report = classification_report(truth_values, pred_values, target_names=class_names,  digits=4)\n",
    "    conf_matrix = confusion_matrix(truth_values, pred_values, normalize='all') \n",
    "    print('[Evalutaion Model] Showing detailed report\\n')\n",
    "    print(report)\n",
    "    print('[Evalutaion Model] Showing confusion matrix')\n",
    "    print(f'                       Predicted Label              ')\n",
    "    print(f'                         0            1         ')\n",
    "    print(f' Truth Label     0   {conf_matrix[0][0]:4f}     {conf_matrix[0][1]:4f}')\n",
    "    print(f'                 1   {conf_matrix[1][0]:4f}     {conf_matrix[1][1]:4f}')\n",
    "    \n",
    "    \n",
    "def save_classification_report(truth_values, pred_values, out_report_dir):\n",
    "    \"\"\"\n",
    "    Save the classification report and confusion matrix to a text file.\n",
    "\n",
    "    Args:\n",
    "        truth_values (list): List of ground truth labels.\n",
    "        pred_values (list): List of predicted labels.\n",
    "        out_report_dir (str): Directory path to save the classification report file.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    print('[INFO] Saving report...')\n",
    "    c_report = classification_report(truth_values, pred_values, target_names=class_names,  digits=4)\n",
    "    conf_matrix = confusion_matrix(truth_values, pred_values, normalize='all') \n",
    "    matrix_report = ['                       Predicted Label              ', \n",
    "                     f'                         0            1         ',\n",
    "                     f' Truth Label     0   {conf_matrix[0][0]:4f}     {conf_matrix[0][1]:4f}',\n",
    "                     f'                 1   {conf_matrix[1][0]:4f}     {conf_matrix[1][1]:4f}']\n",
    "    \n",
    "    with open(out_report_dir, 'w') as f:\n",
    "        f.write(c_report)\n",
    "        f.write('\\n')\n",
    "        for line in matrix_report:\n",
    "            f.write(line)\n",
    "            f.write('\\n')\n",
    "            \n",
    "\n",
    "def get_features(vgg, file=TRAIN):\n",
    "    \"\"\"\n",
    "    Extract features and labels from the VGG-16 model for a given dataset.\n",
    "\n",
    "    Args:\n",
    "        vgg (torchvision.models.vgg16): VGG-16 model with removed classifier.\n",
    "        file (str, optional): Name of the dataset directory. Defaults to TRAIN.\n",
    "\n",
    "    Returns:\n",
    "        svm_features (list): List of feature vectors for the dataset.\n",
    "        svm_labels (list): List of corresponding labels for the dataset.\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Getting '{file}' features...\")\n",
    "    svm_features = []\n",
    "    svm_labels = []\n",
    "    data_batches_len = len(dataloaders[file])\n",
    "    for i, data_batch in enumerate(dataloaders[file]):\n",
    "        print(f\"\\r[FEATURE] Loading batch {i + 1}/{data_batches_len} ({len(data_batch[1])*(i+1)} images)\", end='', flush=True)\n",
    "        # In this case, loaded databatch of 8 images including 8 features and 8 labels\n",
    "        inputs, labels = data_batch\n",
    "        if use_gpu:\n",
    "            # Get the data through the feature extractor of VGG16\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            # Extract data from VGG16 feature extractor as a vector\n",
    "            features = vgg(inputs)\n",
    "            # print(features.shape)     # torch.Size([8, 25088])\n",
    "            # print(labels.shape)       # torch.Size([8])\n",
    "            features = features.cpu().detach().numpy()\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "        else:\n",
    "            # Get the data through the feature extractor of VGG16\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            # Extract data from VGG16 feature extractor as a vector\n",
    "            features = vgg(inputs)\n",
    "            features = features.detach().numpy()\n",
    "            labels = labels.detach().numpy()\n",
    "        \n",
    "        # Add feature with correct label into an array\n",
    "        # print(features.shape)     # (8, 25088)\n",
    "        # print(labels.shape)       # (8,)\n",
    "        for index in range(len(labels)):\n",
    "            feature = features[index]  \n",
    "            label = labels[index]\n",
    "            # Add it to the features list\n",
    "            # print(feature.shape)     # (25088,)\n",
    "            svm_features.append(feature)\n",
    "            # print(label.shape)       # (1)\n",
    "            svm_labels.append(label)\n",
    "            \n",
    "    print(\"\\n[FEATURE] Features loaded\")\n",
    "    return svm_features, svm_labels\n",
    "\n",
    "\n",
    "def svm_classifier(train_data, test_data):\n",
    "    \"\"\"\n",
    "    Train an SVM classifier on the extracted features and evaluate its performance.\n",
    "\n",
    "    Args:\n",
    "        train_data (list): [svm_train_features, svm_train_labels], where svm_train_features is a list of training feature vectors,\n",
    "                           and svm_train_labels is a list of corresponding training labels.\n",
    "        test_data (list): [svm_test_features, svm_test_labels], where svm_test_features is a list of test feature vectors,\n",
    "                          and svm_test_labels is a list of corresponding test labels.\n",
    "\n",
    "    Returns:\n",
    "        svm_model (sklearn.svm.SVC): Trained SVM classifier.\n",
    "        score (float): Accuracy score of the trained SVM classifier on the test dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    since = time.time()\n",
    "    FEATURE_INDEX = 0\n",
    "    LABEL_INDEX = 1\n",
    "    print('[INFO] Getting model...')\n",
    "    # There are 1000 images in the train data\n",
    "    train_features = np.array(train_data[FEATURE_INDEX])\n",
    "    # print(features.shape)     # (1000, 25088)\n",
    "    train_labels = np.array(train_data[LABEL_INDEX])\n",
    "    # print(labels.shape)       # (1000,)\n",
    "    \n",
    "    # There are 600 images in the test data\n",
    "    test_features = np.array(test_data[FEATURE_INDEX])\n",
    "    # print(features.shape)     # (1000, 25088)\n",
    "    test_labels = np.array(test_data[LABEL_INDEX])\n",
    "    # print(labels.shape)       # (1000,)\n",
    "    \n",
    "    # Create model\n",
    "    svm_model = SVC(gamma=\"auto\")\n",
    "    # Train model\n",
    "    print('[INFO] Fitting...')\n",
    "    svm_model.fit(train_features, train_labels)\n",
    "    print('[INFO] Model completed')\n",
    "    # Get result\n",
    "    print('[INFO] Testing...')\n",
    "    pred_labels = svm_model.predict(test_features)\n",
    "    print('[INFO] Printing classification report')\n",
    "    get_classification_report(test_labels, pred_labels)\n",
    "    elapsed_time = time.time() - since\n",
    "    print(f\"[INFO] Model produced in {(elapsed_time // 60):.0f}m {(elapsed_time % 60):.0f}s\")\n",
    "    save_classification_report(test_labels, pred_labels, out_report_dir)\n",
    "    return svm_model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use GPU if available. Note that this only to load features using VGG16. Scikit Learn SVM does not support GPU\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    print(\"[INFO] Using CUDA\") if use_gpu else print(\"[INFO] Using CPU\")\n",
    "    # Get Data\n",
    "    datasets_img, datasets_size, dataloaders, class_names = get_data(file_dir)\n",
    "    # Get VGG16 pre-trained model\n",
    "    vgg16 = get_vgg16_modified_model()\n",
    "    # Move model to GPU\n",
    "    if use_gpu:\n",
    "        torch.cuda.empty_cache()\n",
    "        vgg16.cuda()\n",
    "    # Extract features and labels from the VGG16 model\n",
    "    svm_train_features, svm_train_labels = get_features(vgg16, TRAIN)\n",
    "    svm_test_features, svm_test_labels = get_features(vgg16, TEST)\n",
    "    # Run SVM \n",
    "    svm_model = svm_classifier(\n",
    "        [svm_train_features, svm_train_labels],\n",
    "        [svm_test_features, svm_test_labels],\n",
    "    )\n",
    "    # Save model\n",
    "    print('[INFO] Saving model...')\n",
    "    pickle.dump(svm_model, open(output_dir, 'wb'))\n",
    "    print('[INFO] Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
